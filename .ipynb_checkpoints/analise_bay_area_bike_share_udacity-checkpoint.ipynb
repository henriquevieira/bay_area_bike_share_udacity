{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "\n",
    "# 201309_trip_data.csv\n",
    "# 201309_trip_summary.csv\n",
    "# 201402_README.txt\n",
    "# 201402_station_data.csv\n",
    "# 201402_trip_data.csv\n",
    "# 201402_weather_data.csv\n",
    "# 201408_README.txt\n",
    "# 201408_station_data.csv\n",
    "# 201408_trip_data.csv\n",
    "# 201408_weather_data.csv\n",
    "# 201508_README.txt\n",
    "# 201508_station_data.csv\n",
    "# 201508_trip_data.csv\n",
    "# 201508_weather_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA\n",
    "df_201402_station = pd.read_csv('ndfdsi-bikeshareanalysis/201402_station_data.csv')\n",
    "df_201402_trip = pd.read_csv('ndfdsi-bikeshareanalysis/201402_trip_data.csv')\n",
    "df_201402_weather = pd.read_csv('ndfdsi-bikeshareanalysis/201402_weather_data.csv')\n",
    "\n",
    "df_201408_station = pd.read_csv('ndfdsi-bikeshareanalysis/201408_station_data.csv')\n",
    "df_201408_trip = pd.read_csv('ndfdsi-bikeshareanalysis/201408_trip_data.csv')\n",
    "df_201408_weather = pd.read_csv('ndfdsi-bikeshareanalysis/201408_weather_data.csv')\n",
    "\n",
    "df_201508_station = pd.read_csv('ndfdsi-bikeshareanalysis/201508_station_data.csv')\n",
    "df_201508_trip = pd.read_csv('ndfdsi-bikeshareanalysis/201508_trip_data.csv')\n",
    "df_201508_weather = pd.read_csv('ndfdsi-bikeshareanalysis/201508_weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE\t\t\tNROW\tNCOL\n",
      "df_201402_station\t69\t7\n",
      "df_201408_station\t70\t7\n",
      "df_201508_station\t70\t7\n",
      "df_201402_trip\t\t144015\t11\n",
      "df_201408_trip\t\t171792\t11\n",
      "df_201508_trip\t\t354152\t11\n",
      "df_201402_weather\t920\t24\n",
      "df_201408_weather\t920\t24\n",
      "df_201508_weather\t1825\t24\n"
     ]
    }
   ],
   "source": [
    "# CHECK d201402 DATA SIZE\n",
    "# CHECK d201408 DATA SIZE\n",
    "# CHECK d201508 DATA SIZE\n",
    "print(\"TABLE\\t\\t\\tNROW\\tNCOL\")\n",
    "print(\"df_201402_station\\t\" + str(df_201402_station.shape[0]) + \"\\t\" + str(df_201402_station.shape[1]))\n",
    "print(\"df_201408_station\\t\" + str(df_201408_station.shape[0]) + \"\\t\" + str(df_201408_station.shape[1]))\n",
    "print(\"df_201508_station\\t\" + str(df_201508_station.shape[0]) + \"\\t\" + str(df_201508_station.shape[1]))\n",
    "\n",
    "print(\"df_201402_trip\\t\\t\" + str(df_201402_trip.shape[0]) + \"\\t\" + str(df_201402_trip.shape[1]))\n",
    "print(\"df_201408_trip\\t\\t\" + str(df_201408_trip.shape[0]) + \"\\t\" + str(df_201408_trip.shape[1]))\n",
    "print(\"df_201508_trip\\t\\t\" + str(df_201508_trip.shape[0]) + \"\\t\" + str(df_201508_trip.shape[1]))\n",
    "\n",
    "print(\"df_201402_weather\\t\" + str(df_201402_weather.shape[0]) + \"\\t\" + str(df_201402_weather.shape[1]))\n",
    "print(\"df_201408_weather\\t\" + str(df_201408_weather.shape[0]) + \"\\t\" + str(df_201408_weather.shape[1]))\n",
    "print(\"df_201508_weather\\t\" + str(df_201508_weather.shape[0]) + \"\\t\" + str(df_201508_weather.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE COLUMN NAME\n",
    "df_201402_station.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201402_trip.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201402_weather.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201408_station.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201408_trip.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201408_weather.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201508_station.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201508_trip.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)\n",
    "df_201508_weather.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PROCESS DATA ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK IF STATION TABLE COLUMN NAME IS EQUAL\n",
    "df_201402_station.columns.tolist() == df_201408_station.columns.tolist() == df_201508_station.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE\t\tNROW\tNCOL\tNDUPLICATES\n",
      "df_station\t209\t8\t0\n",
      "\n",
      "Remove the duplicated data\n",
      "\n",
      "TABLE\t\tNROW\tNCOL\tNDUPLICATES\n",
      "df_station\t209\t8\t0\n"
     ]
    }
   ],
   "source": [
    "# ADD DATA COLUMN\n",
    "df_201402_station['data'] = np.repeat('201402', df_201402_station.shape[0])\n",
    "df_201408_station['data'] = np.repeat('201408', df_201408_station.shape[0])\n",
    "df_201508_station['data'] = np.repeat('201508', df_201508_station.shape[0])\n",
    "\n",
    "# MERGE STATION TABLES\n",
    "df_stations_data = [df_201402_station, df_201408_station, df_201508_station]\n",
    "df_station = pd.concat(df_stations_data)\n",
    "\n",
    "# PRINT STATION TABLE SIZE, NUM OF DUPLICATES\n",
    "print(\"TABLE\\t\\tNROW\\tNCOL\\tNDUPLICATES\")\n",
    "print(\"df_station\\t\" + str(df_station.shape[0]) + \n",
    "      \"\\t\" + str(df_station.shape[1]) + \n",
    "      \"\\t\" + str(sum(df_station.duplicated())))\n",
    "\n",
    "# REMOVENDO AS DUPLICATAS\n",
    "print(\"\\nRemove the duplicated data\\n\")\n",
    "df_station.drop_duplicates(inplace=True)\n",
    "\n",
    "# PRINT STATION TABLE SIZE, NUM OF DUPLICATES\n",
    "print(\"TABLE\\t\\tNROW\\tNCOL\\tNDUPLICATES\")\n",
    "print(\"df_station\\t\" + str(df_station.shape[0]) + \n",
    "      \"\\t\" + str(df_station.shape[1]) + \n",
    "      \"\\t\" + str(sum(df_station.duplicated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK IF TRIP TABLE COLUMN NAME IS EQUAL\n",
    "df_201402_trip.columns.tolist() == df_201408_trip.columns.tolist() == df_201508_trip.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_201402_trip x df_201408_trip\n",
      "IS EQUAL\tCOLUMN NAME\n",
      "True\t\t|trip_id|----|trip_id|\n",
      "True\t\t|duration|----|duration|\n",
      "True\t\t|start_date|----|start_date|\n",
      "True\t\t|start_station|----|start_station|\n",
      "True\t\t|start_terminal|----|start_terminal|\n",
      "True\t\t|end_date|----|end_date|\n",
      "True\t\t|end_station|----|end_station|\n",
      "True\t\t|end_terminal|----|end_terminal|\n",
      "True\t\t|bike_#|----|bike_#|\n",
      "False\t\t|subscription_type|----|subscriber_type|\n",
      "True\t\t|zip_code|----|zip_code|\n",
      "Total False: 1\n",
      "\n",
      "----------//----------\n",
      "\n",
      "df_201402_trip x df_201508_trip\n",
      "IS EQUAL\tCOLUMN NAME\n",
      "True\t\t|trip_id|----|trip_id|\n",
      "True\t\t|duration|----|duration|\n",
      "True\t\t|start_date|----|start_date|\n",
      "True\t\t|start_station|----|start_station|\n",
      "True\t\t|start_terminal|----|start_terminal|\n",
      "True\t\t|end_date|----|end_date|\n",
      "True\t\t|end_station|----|end_station|\n",
      "True\t\t|end_terminal|----|end_terminal|\n",
      "True\t\t|bike_#|----|bike_#|\n",
      "False\t\t|subscription_type|----|subscriber_type|\n",
      "True\t\t|zip_code|----|zip_code|\n",
      "Total False: 1\n"
     ]
    }
   ],
   "source": [
    "# COMPARE COLUMN NAMES BETWEEN TRIP TABLES\n",
    "print(\"df_201402_trip x df_201408_trip\")\n",
    "print(\"IS EQUAL\\tCOLUMN NAME\")\n",
    "name_equal_trip_1 = []\n",
    "for i in range(df_201402_trip.shape[1]):\n",
    "    check = df_201402_trip.columns.tolist()[i] == df_201408_trip.columns.tolist()[i]\n",
    "    name_equal_trip_1.append(not check)    \n",
    "    print(str(check) + \"\\t\\t\" + \n",
    "          \"|\" + str(df_201402_trip.columns.tolist()[i]) + \n",
    "          \"|----|\" + \n",
    "          str(df_201408_trip.columns.tolist()[i]) + \"|\" ) \n",
    "print(\"Total False: \"+str(sum(name_equal_trip_1)))\n",
    "\n",
    "print(\"\\n----------//----------\\n\")\n",
    "\n",
    "print(\"df_201402_trip x df_201508_trip\")\n",
    "print(\"IS EQUAL\\tCOLUMN NAME\")\n",
    "name_equal_trip_2 = []\n",
    "for i in range(df_201402_trip.shape[1]):\n",
    "    check = df_201402_trip.columns.tolist()[i] == df_201508_trip.columns.tolist()[i]\n",
    "    name_equal_trip_2.append(not check)\n",
    "    print(str(check) + \"\\t\\t\" + \n",
    "          \"|\" + str(df_201402_trip.columns.tolist()[i]) +\n",
    "          \"|----|\" + \n",
    "          str(df_201508_trip.columns.tolist()[i]) + \"|\"  )\n",
    "print(\"Total False: \"+str(sum(name_equal_trip_2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is same the columns with differ names?\n",
      "True\n",
      "\n",
      "Change names...\n",
      "\n",
      "Is equal the columns name?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# CHECANDO SE SAO AS MESMAS COLUNAS COM NOMES DIFERENTES\n",
    "print(\"Is same the columns with differ names?\\n\" + str(name_equal_trip_1 == name_equal_trip_2))\n",
    "\n",
    "# CHANGE COLUMN NAMES\n",
    "print(\"\\nChange names...\\n\")\n",
    "colnames = df_201402_trip.columns.tolist()\n",
    "df_201408_trip.columns = colnames\n",
    "df_201508_trip.columns = colnames\n",
    "\n",
    "# CHECK IF TRIP TABLE COLUMN NAME IS EQUAL\n",
    "print(\"Is equal the columns name?\\n\" + \n",
    "     str(df_201402_trip.columns.tolist() == df_201408_trip.columns.tolist() == df_201508_trip.columns.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE\t\tNROW\tNCOL\tNDUPLICATES\n",
      "df_trip\t\t669959\t12\t0\n"
     ]
    }
   ],
   "source": [
    "# ADD DATA COLUMN\n",
    "df_201402_trip['data'] = np.repeat('201402', df_201402_trip.shape[0])\n",
    "df_201408_trip['data'] = np.repeat('201408', df_201408_trip.shape[0])\n",
    "df_201508_trip['data'] = np.repeat('201508', df_201508_trip.shape[0])\n",
    "\n",
    "# MERGE TRIP TABLES\n",
    "df_trips_data = [df_201402_trip, df_201408_trip, df_201508_trip]\n",
    "df_trip = pd.concat(df_trips_data)\n",
    "\n",
    "# PRINT TRIP TABLE SIZE, NUM OF DUPLICATES\n",
    "print(\"TABLE\\t\\tNROW\\tNCOL\\tNDUPLICATES\")\n",
    "print(\"df_trip\\t\\t\" + str(df_trip.shape[0]) + \n",
    "      \"\\t\" + str(df_trip.shape[1]) + \n",
    "      \"\\t\" + str(sum(df_trip.duplicated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_201402_weather x df_201408_weather\n",
      "IS EQUAL\tCOLUMN NAME\n",
      "False\t\t|date|----|pdt|\n",
      "False\t\t|max_temperature_f|----|max_temperaturef|\n",
      "False\t\t|mean_temperature_f|----|mean_temperaturef|\n",
      "True\t\t|min_temperaturef|----|min_temperaturef|\n",
      "False\t\t|max_dew_point_f|----|max_dew_pointf|\n",
      "False\t\t|meandew_point_f|----|meandew_pointf|\n",
      "False\t\t|min_dewpoint_f|----|min_dewpointf|\n",
      "True\t\t|max_humidity|----|max_humidity|\n",
      "True\t\t|mean_humidity|----|mean_humidity|\n",
      "True\t\t|min_humidity|----|min_humidity|\n",
      "False\t\t|max_sea_level_pressure_in|----|max_sea_level_pressurein|\n",
      "False\t\t|mean_sea_level_pressure_in|----|mean_sea_level_pressurein|\n",
      "False\t\t|min_sea_level_pressure_in|----|min_sea_level_pressurein|\n",
      "False\t\t|max_visibility_miles|----|max_visibilitymiles|\n",
      "False\t\t|mean_visibility_miles|----|mean_visibilitymiles|\n",
      "False\t\t|min_visibility_miles|----|min_visibilitymiles|\n",
      "False\t\t|max_wind_speed_mph|----|max_wind_speedmph|\n",
      "False\t\t|mean_wind_speed_mph|----|mean_wind_speedmph|\n",
      "False\t\t|max_gust_speed_mph|----|max_gust_speedmph|\n",
      "False\t\t|precipitation_in|----|precipitationin|\n",
      "False\t\t|cloud_cover|----|cloudcover|\n",
      "True\t\t|events|----|events|\n",
      "False\t\t|wind_dir_degrees|----|winddirdegrees|\n",
      "True\t\t|zip|----|zip|\n",
      "Total False: 18\n",
      "\n",
      "----------//----------\n",
      "\n",
      "df_201402_weather x df_201408_weather\n",
      "IS EQUAL\tCOLUMN NAME\n",
      "False\t\t|date|----|pdt|\n",
      "False\t\t|max_temperature_f|----|max_temperaturef|\n",
      "False\t\t|mean_temperature_f|----|mean_temperaturef|\n",
      "True\t\t|min_temperaturef|----|min_temperaturef|\n",
      "False\t\t|max_dew_point_f|----|max_dew_pointf|\n",
      "False\t\t|meandew_point_f|----|meandew_pointf|\n",
      "False\t\t|min_dewpoint_f|----|min_dewpointf|\n",
      "True\t\t|max_humidity|----|max_humidity|\n",
      "True\t\t|mean_humidity|----|mean_humidity|\n",
      "True\t\t|min_humidity|----|min_humidity|\n",
      "False\t\t|max_sea_level_pressure_in|----|max_sea_level_pressurein|\n",
      "False\t\t|mean_sea_level_pressure_in|----|mean_sea_level_pressurein|\n",
      "False\t\t|min_sea_level_pressure_in|----|min_sea_level_pressurein|\n",
      "False\t\t|max_visibility_miles|----|max_visibilitymiles|\n",
      "False\t\t|mean_visibility_miles|----|mean_visibilitymiles|\n",
      "False\t\t|min_visibility_miles|----|min_visibilitymiles|\n",
      "False\t\t|max_wind_speed_mph|----|max_wind_speedmph|\n",
      "False\t\t|mean_wind_speed_mph|----|mean_wind_speedmph|\n",
      "False\t\t|max_gust_speed_mph|----|max_gust_speedmph|\n",
      "False\t\t|precipitation_in|----|precipitationin|\n",
      "False\t\t|cloud_cover|----|cloudcover|\n",
      "True\t\t|events|----|events|\n",
      "False\t\t|wind_dir_degrees|----|winddirdegrees|\n",
      "True\t\t|zip|----|zip|\n",
      "Total False: 18\n"
     ]
    }
   ],
   "source": [
    "# COMPARE COLUMN NAMES BETWEEN WEATHER TABLES\n",
    "print(\"df_201402_weather x df_201408_weather\")\n",
    "print(\"IS EQUAL\\tCOLUMN NAME\")\n",
    "name_equal_weather_1 = []\n",
    "for i in range(df_201402_weather.shape[1]):\n",
    "    check = df_201402_weather.columns.tolist()[i] == df_201408_weather.columns.tolist()[i]\n",
    "    name_equal_weather_1.append(not check)\n",
    "    print(str(check) + \"\\t\\t\" + \n",
    "          \"|\" + str(df_201402_weather.columns.tolist()[i]) +\n",
    "          \"|----|\" + \n",
    "          str(df_201408_weather.columns.tolist()[i]) + \"|\" )\n",
    "print(\"Total False: \"+str(sum(name_equal_weather_1)))\n",
    "\n",
    "print(\"\\n----------//----------\\n\")\n",
    "\n",
    "print(\"df_201402_weather x df_201408_weather\")\n",
    "print(\"IS EQUAL\\tCOLUMN NAME\")\n",
    "name_equal_weather_2 = []\n",
    "for i in range(df_201402_weather.shape[1]):\n",
    "    check = df_201402_weather.columns.tolist()[i] == df_201508_weather.columns.tolist()[i]\n",
    "    name_equal_weather_2.append(not check)\n",
    "    print(str(check) + \"\\t\\t\" + \n",
    "          \"|\" + str(df_201402_weather.columns.tolist()[i]) +\n",
    "          \"|----|\" + \n",
    "          str(df_201508_weather.columns.tolist()[i]) + \"|\" )\n",
    "print(\"Total False: \"+str(sum(name_equal_weather_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is same the columns with differ names?\n",
      "True\n",
      "\n",
      "Change names...\n",
      "\n",
      "Is equal the columns name?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# CHECANDO SE SAO AS MESMAS COLUNAS COM NOMES DIFERENTES\n",
    "print(\"Is same the columns with differ names?\\n\" + str(name_equal_weather_1 == name_equal_weather_2))\n",
    "\n",
    "# CHANGE COLUMN NAMES\n",
    "print(\"\\nChange names...\\n\")\n",
    "colnames = df_201402_weather.columns.tolist()\n",
    "df_201408_weather.columns = colnames\n",
    "df_201508_weather.columns = colnames\n",
    "\n",
    "# CHECK IF TRIP TABLE COLUMN NAME IS EQUAL\n",
    "print(\"Is equal the columns name?\\n\" + \n",
    "     str(df_201402_weather.columns.tolist() == df_201408_weather.columns.tolist() == df_201508_weather.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE\t\tNROW\tNCOL\tNDUPLICATES\n",
      "df_trip\t\t3665\t25\t0\n"
     ]
    }
   ],
   "source": [
    "# ADD DATA COLUMN\n",
    "df_201402_weather['data'] = np.repeat('201402', df_201402_weather.shape[0])\n",
    "df_201408_weather['data'] = np.repeat('201408', df_201408_weather.shape[0])\n",
    "df_201508_weather['data'] = np.repeat('201508', df_201508_weather.shape[0])\n",
    "\n",
    "# MERGE WEATHER TABLES\n",
    "df_weathers_data = [df_201402_weather, df_201408_weather, df_201508_weather]\n",
    "df_weather = pd.concat(df_weathers_data)\n",
    "\n",
    "# PRINT TRIP TABLE SIZE, NUM OF DUPLICATES\n",
    "print(\"TABLE\\t\\tNROW\\tNCOL\\tNDUPLICATES\")\n",
    "print(\"df_trip\\t\\t\" + str(df_weather.shape[0]) + \n",
    "      \"\\t\" + str(df_weather.shape[1]) + \n",
    "      \"\\t\" + str(sum(df_weather.duplicated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables sizes\n",
      "TABLE\t\tNROW\tNCOL\tNDUPLICATES\n",
      "df_station\t209\t8\t0\n",
      "df_trip\t\t669959\t12\t0\n",
      "df_trip\t\t3665\t25\t0\n"
     ]
    }
   ],
   "source": [
    "# CHECK TABLES SIZES\n",
    "\n",
    "print(\"Tables sizes\")\n",
    "print(\"TABLE\\t\\tNROW\\tNCOL\\tNDUPLICATES\")\n",
    "print(\"df_station\\t\" + str(df_station.shape[0]) + \n",
    "      \"\\t\" + str(df_station.shape[1]) + \n",
    "      \"\\t\" + str(sum(df_station.duplicated())))\n",
    "print(\"df_trip\\t\\t\" + str(df_trip.shape[0]) + \n",
    "      \"\\t\" + str(df_trip.shape[1]) + \n",
    "      \"\\t\" + str(sum(df_trip.duplicated())))\n",
    "print(\"df_trip\\t\\t\" + str(df_weather.shape[0]) + \n",
    "      \"\\t\" + str(df_weather.shape[1]) + \n",
    "      \"\\t\" + str(sum(df_weather.duplicated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# ANALISES #\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P1: Escreva pelo menos duas perguntas que você acha que poderiam ser respondidas usando os dados.\n",
    "# - Há periodos sazonais de uso das bicicletas ao longo do ano?\n",
    "# - Podemos identificar grupos de usuarios de bicicletas, atraves do seu perfil tempo percorrido entre as estações?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 669959 entries, 0 to 354151\n",
      "Data columns (total 11 columns):\n",
      "trip_id              669959 non-null int64\n",
      "duration             669959 non-null int64\n",
      "start_date           669959 non-null object\n",
      "start_station        669959 non-null object\n",
      "start_terminal       669959 non-null int64\n",
      "end_date             669959 non-null object\n",
      "end_station          669959 non-null object\n",
      "end_terminal         669959 non-null int64\n",
      "bike_#               669959 non-null int64\n",
      "subscription_type    669959 non-null object\n",
      "zip_code             663340 non-null object\n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 61.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_trip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data    bike_#\n",
       "201402  9          119557\n",
       "        10         132942\n",
       "        11          51243\n",
       "        12         137726\n",
       "        13         393129\n",
       "        14          65621\n",
       "        15          47022\n",
       "        16         177235\n",
       "        17         227893\n",
       "        18          51222\n",
       "        19          73657\n",
       "        20          55646\n",
       "        21          40141\n",
       "        22          80671\n",
       "        23          30745\n",
       "        24          55337\n",
       "        25          39683\n",
       "        26         155188\n",
       "        27          47196\n",
       "        28         107731\n",
       "        29          30866\n",
       "        30         231181\n",
       "        31          59707\n",
       "        32          16066\n",
       "        34          14907\n",
       "        35         106412\n",
       "        36          38689\n",
       "        37         182176\n",
       "        38         132857\n",
       "        39          30576\n",
       "                   ...   \n",
       "201508  689        177745\n",
       "        690         65086\n",
       "        691         95832\n",
       "        692        882835\n",
       "        693        148827\n",
       "        694        129921\n",
       "        695        233389\n",
       "        696         72187\n",
       "        698         99607\n",
       "        699         84444\n",
       "        700        110187\n",
       "        701        275948\n",
       "        702        261216\n",
       "        703        368342\n",
       "        704        199453\n",
       "        705        134418\n",
       "        706        126727\n",
       "        707        176999\n",
       "        708        109021\n",
       "        709        647693\n",
       "        710        385090\n",
       "        711        257685\n",
       "        712        149759\n",
       "        713        457215\n",
       "        714        256306\n",
       "        715        185732\n",
       "        716        124899\n",
       "        740         82046\n",
       "        877        686411\n",
       "        878       1006812\n",
       "Name: duration, Length: 2038, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trip.groupby(['data', 'bike_#'])['duration'].sum()\n",
    "# df_trip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data\n",
       "201402     15\n",
       "201408     92\n",
       "201508    144\n",
       "Name: bike_#, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_trip[df_trip['bike_#'] == 9]\n",
    "\n",
    "# sum(df_trip['bike_#'] == 9)\n",
    "df_trip[df_trip['bike_#'] == 9].groupby('data')['bike_#'].count()\n",
    "\n",
    "# d = df_trip[df_trip['bike_#'] == 9]\n",
    "\n",
    "# d[d['data'] == '201402'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_station.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
